#!/usr/bin/env python3

from urllib import response
import rclpy
from rclpy.node import Node
import logging
import cv2
from PIL import Image
from langchain_google_vertexai import ChatVertexAI
import time
import base64
import time
from langchain_google_vertexai import ChatVertexAI
from langchain_core.messages import HumanMessage 
from io import BytesIO

class MiniPupperMazeService(Node):

    def __init__(self):
        super().__init__('mini_pupper_maze_service')

        self.ai_response_publisher_ = self.create_publishe(Ai_response,
                                       'ai_response',
                                       self._maze_callback)

    def take_photo():
        """
        Captures a photo from the webcam and returns it as a PIL Image object.

        Returns:
        - image (PIL.Image): The captured image or None if the webcam is not accessible.
        """
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            return None

        ret, frame = cap.read()
        image = None
        if ret:
            image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        cap.release()
        return image

    def ai_image_response(llm, image, text):
        """
        Generates a response from the AI model based on the provided image and text.

        Parameters:
        - llm (ChatVertexAI): The AI model instance for processing images.
        - image (PIL.Image): The image object to be processed.
        - text (str): The accompanying text for the image.

        Returns:
        - result (str): The text response generated by the AI model.
        """
        logging.debug("ai_image_response start!")
        ms_start = int(time.time() * 1000)

        buffered = BytesIO()
        image.save(buffered, format="JPEG")
        image_bytes = buffered.getvalue()

        image_base64 = base64.b64encode(image_bytes).decode('utf-8')
        image_data_url = f"data:image/jpeg;base64,{image_base64}"

        image_message = {
            "type": "image_url",
            "image_url": {
                "url": image_data_url
            }
        }
        text_message = {"type": "text", "text": text}

        message = HumanMessage(content=[text_message, image_message])

        output = llm.invoke([message])

        #logging.debug(f"ai_image_response response: {output}")
        result = output.content
        logging.debug(f"text response: {result}")
        ms_end = int(time.time() * 1000)
        logging.debug(f"ai_image_response end, delay = {ms_end - ms_start}ms")
        return result

    def image_recognition():

        direction_input_prompt="""
        You are an expert in identifying the degree of black line from the image
                    and tell how to move along the line
                    in below format

                    [
                        'move_forward',
                        'look_middle',
                        'look_down',
                        'look_up',
                        'move_backward',
                        'look_left',
                        'look_right',
                        'move_left',
                        'move_right',
                        'move_forward',
                        'move_backward',
                        'look_middle',
                        'look_left',
                        'look_right'
                    ]

        """

        sharp_direction_input_prompt="""
        You are an expert in identifying pointers of different direction from the image
                    and tell what directions are they
                    in below format only if you see a pointer pointing to the right and output a "." if you dont see a pointer

                    [
                        'move_right',
                        'move_right',
                        'move_right',
                        'move_right',
                        'move_right',
                        'move_right',
                        'move_right',
                        'move_right',
                        'move_right',
                        'move_right',
                        'move_right',
                        'move_right',
                    ]
        """

        multi_model = ChatVertexAI(model="gemini-pro-vision")

        image = take_photo()
        image = image.resize((320, 240))
        direction_response = ai_image_response(multi_model, image=image, text=direction_input_prompt)
        sharp_direction_response = ai_image_response(multi_model, image=image, text=sharp_direction_input_prompt)

        if sharp_direction_response == "." :
            self.response_publisher_.publish(direction_response)
        else:
            self.response_publisher_.publish(sharp_direction_response)

def main():
    rclpy.init()
    minimal_service = MiniPupperMazeService()
    rclpy.spin(minimal_service)


if __name__ == '__main__':
    main()